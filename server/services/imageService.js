import { GoogleGenAI } from "@google/genai";
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';
import { v4 as uuidv4 } from 'uuid';
import { storageService } from './storageService.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

class ImageGenerationService {
  constructor() {
    this.aiInstance = null;
    this.lastUsedApiKey = null;
  }

  // è·å– Google AI å®ä¾‹
  getGoogleAI() {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      throw new Error("æœªæ‰¾åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡");
    }

    // å¦‚æœ API key æ”¹å˜äº†ï¼Œé‡æ–°åˆå§‹åŒ–å®ä¾‹
    if (!this.aiInstance || apiKey !== this.lastUsedApiKey) {
      try {
        this.aiInstance = new GoogleGenAI({ apiKey });
        this.lastUsedApiKey = apiKey;
      } catch (e) {
        console.error("åˆå§‹åŒ– GoogleGenAI å¤±è´¥", e);
        throw new Error(`åˆå§‹åŒ– AI æœåŠ¡å¤±è´¥: ${e.message}`);
      }
    }

    return this.aiInstance;
  }

  // å¤„ç† API é”™è¯¯
  handleApiError(error, action) {
    console.error(`API call for "${action}" failed:`, error);
    let message = `åœ¨"${action}"æœŸé—´å‘ç”Ÿé”™è¯¯: ${error.message || 'æœªçŸ¥é€šä¿¡é”™è¯¯'}`;
    
    try {
      const errorObj = JSON.parse(error.message);
      if (errorObj?.error?.message) {
        message = `åœ¨"${action}"æœŸé—´å‘ç”Ÿé”™è¯¯: ${errorObj.error.message}`;
      }
    } catch(e) {
      if (String(error.message).includes('API key not valid')) {
        message = 'API å¯†é’¥æ— æ•ˆã€‚è¯·æ£€æŸ¥ GEMINI_API_KEY ç¯å¢ƒå˜é‡ã€‚';
      } else if (String(error.message).includes('xhr error')) {
        message = `ä¸ AI æœåŠ¡çš„é€šä¿¡å¤±è´¥ã€‚è¿™å¯èƒ½æ˜¯ç”±ç½‘ç»œé—®é¢˜æˆ–æ— æ•ˆçš„ API å¯†é’¥å¼•èµ·çš„ã€‚`;
      }
    }

    return new Error(message);
  }

  // å°†æ–‡ä»¶è½¬æ¢ä¸º base64
  async fileToBase64(buffer, mimeType) {
    return buffer.toString('base64');
  }

  // å°† Buffer è½¬æ¢ä¸º GenerativePart
  async bufferToGenerativePart(buffer, mimeType) {
    const base64data = await this.fileToBase64(buffer, mimeType);
    return {
      inlineData: {
        mimeType: mimeType,
        data: base64data,
      },
    };
  }

  // å°† multer æ–‡ä»¶è½¬æ¢ä¸º GenerativePart
  async fileToGenerativePart(file) {
    return this.bufferToGenerativePart(file.buffer, file.mimetype);
  }

  // ä¿å­˜ base64 å›¾ç‰‡åˆ°æœ¬åœ°æˆ–äº‘å­˜å‚¨
  async saveBase64Image(base64Data, originalFilename = null) {
    try {
      // æå– base64 æ•°æ®ï¼ˆå»æ‰ data:image/xxx;base64, å‰ç¼€ï¼‰
      const matches = base64Data.match(/^data:([A-Za-z-+\/]+);base64,(.+)$/);
      if (!matches) {
        throw new Error('æ— æ•ˆçš„ base64 å›¾ç‰‡æ•°æ®');
      }
      
      const mimeType = matches[1];
      const imageBuffer = Buffer.from(matches[2], 'base64');
      
      // ç”Ÿæˆæ–‡ä»¶å
      const ext = mimeType.includes('png') ? 'png' : 'jpg';
      const filename = `${uuidv4()}.${ext}`;
      
      // æ ¹æ®é…ç½®é€‰æ‹©å­˜å‚¨æ–¹å¼
      const result = await storageService.saveImage(imageBuffer, filename, mimeType);
      
      return result;
    } catch (error) {
      console.error('ä¿å­˜å›¾ç‰‡å¤±è´¥:', error);
      throw new Error(`ä¿å­˜å›¾ç‰‡å¤±è´¥: ${error.message}`);
    }
  }

  // è°ƒç”¨å›¾ç‰‡ç¼–è¾‘æ¨¡å‹
  async callImageEditingModel(parts, action) {
    const apiCallId = `api_${Date.now()}_${Math.random().toString(36).substr(2, 6)}`;
    
    try {
      console.log(`ğŸ”„ [${apiCallId}] è°ƒç”¨Gemini API - ${action}`);
      console.log(`ğŸ“Š [${apiCallId}] APIè¯·æ±‚è¯¦æƒ…:`, {
        model: 'gemini-2.5-flash-image-preview',
        partsCount: parts.length,
        partsTypes: parts.map(p => p.inlineData ? 'image' : 'text'),
        action: action
      });

      const ai = this.getGoogleAI();
      const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image-preview',
        contents: { parts: parts },
        config: {
          responseModalities: ['IMAGE'],  // åªè¦æ±‚å›¾ç‰‡è¾“å‡º
          temperature: 0.8,  // å¢åŠ åˆ›æ„æ€§
          candidateCount: 1,
        },
      });

      console.log(`ğŸ“¥ [${apiCallId}] APIå“åº”æ¥æ”¶å®Œæˆ`);
      
      const candidate = response.candidates?.[0];
      console.log(`ğŸ” [${apiCallId}] å“åº”åˆ†æ:`, {
        candidatesCount: response.candidates?.length || 0,
        hasCandidate: !!candidate,
        finishReason: candidate?.finishReason,
        contentPartsCount: candidate?.content?.parts?.length || 0,
        safetyRatings: candidate?.safetyRatings?.map(r => ({ category: r.category, probability: r.probability, blocked: r.blocked }))
      });

      if (!candidate || !candidate.content || !candidate.content.parts || candidate.content.parts.length === 0) {
        const finishReason = candidate?.finishReason;
        const safetyRatings = candidate?.safetyRatings;
        
        console.error(`âŒ [${apiCallId}] APIå“åº”æ— æ•ˆ:`, {
          finishReason,
          safetyRatings,
          candidate: candidate ? 'exists but invalid' : 'missing'
        });
        
        let detailedError = `AI did not return a valid result.`;
        if (finishReason) {
          detailedError += ` Reason: ${finishReason}.`;
        }
        if (safetyRatings?.some(r => r.blocked)) {
          detailedError += ` The prompt may have been blocked by safety filters.`;
        }
        throw new Error(detailedError);
      }

      console.log(`ğŸ” [${apiCallId}] è§£æå“åº”å†…å®¹...`);
      for (const [index, part] of candidate.content.parts.entries()) {
        console.log(`ğŸ“ [${apiCallId}] Part ${index + 1}:`, {
          hasInlineData: !!part.inlineData,
          hasText: !!part.text,
          inlineDataType: part.inlineData?.mimeType,
          textLength: part.text?.length
        });
        
        if (part.inlineData) {
          console.log(`âœ… [${apiCallId}] æ‰¾åˆ°å›¾ç‰‡æ•°æ®ï¼Œä¿å­˜ä¸­...`);
          const base64Data = `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
          const result = await this.saveBase64Image(base64Data);
          console.log(`ğŸ‰ [${apiCallId}] å›¾ç‰‡ä¿å­˜æˆåŠŸ:`, {
            imageUrl: result.imageUrl,
            filename: result.filename
          });
          return result;
        }
        
        // è®°å½•æ–‡æœ¬å“åº”ç”¨äºè°ƒè¯•
        if (part.text) {
          console.log(`âš ï¸ [${apiCallId}] æ¨¡å‹è¿”å›äº†æ–‡æœ¬è€Œä¸æ˜¯å›¾ç‰‡:`, {
            textPreview: part.text.substring(0, 200),
            fullTextLength: part.text.length,
            finishReason: candidate?.finishReason
          });
        }
      }
      
      if (candidate.content.parts[0]?.text) {
        const finishReason = candidate?.finishReason;
        let errorMsg = "æ¨¡å‹è¿”å›äº†æ–‡æœ¬è€Œä¸æ˜¯å›¾ç‰‡ã€‚";
        
        if (finishReason === 'SAFETY') {
          errorMsg += " æç¤ºè¯å¯èƒ½è¢«å®‰å…¨è¿‡æ»¤å™¨æ‹¦æˆªï¼Œè¯·å°è¯•ä½¿ç”¨æ›´ç®€å•çš„æè¿°ã€‚";
        } else {
          errorMsg += " è¯·å°è¯•ç®€åŒ–æç¤ºè¯æˆ–ä½¿ç”¨ä¸åŒçš„æè¿°æ–¹å¼ã€‚";
        }
        
        console.error(`âŒ [${apiCallId}] ${errorMsg}`);
        throw new Error(errorMsg);
      }

      console.error(`âŒ [${apiCallId}] AIæœªè¿”å›é¢„æœŸç»“æœ`);
      throw new Error('AI æœªèƒ½è¿”å›é¢„æœŸçš„å›¾ç‰‡ç»“æœã€‚');
    } catch (e) {
      console.error(`ğŸ’¥ [${apiCallId}] APIè°ƒç”¨å¼‚å¸¸:`, {
        error: e.message,
        stack: e.stack?.split('\n').slice(0, 5)
      });
      
      if (e instanceof Error && (e.message.includes("Model responded with text") || e.message.includes("AI did not return a valid result"))) {
        throw e;
      }
      throw this.handleApiError(e, action);
    }
  }

  // ä»æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡
  async generateImageFromText(prompt, aspectRatio) {
    try {
      const ai = this.getGoogleAI();
      const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt,
        config: {
          numberOfImages: 1,
          outputMimeType: 'image/png',
          aspectRatio: aspectRatio,
        },
      });

      if (response.generatedImages && response.generatedImages.length > 0) {
        const base64ImageBytes = response.generatedImages[0].image.imageBytes;
        const base64Data = `data:image/png;base64,${base64ImageBytes}`;
        const result = await this.saveBase64Image(base64Data);
        return result;
      }
      throw new Error('AI æœªèƒ½ç”Ÿæˆå›¾ç‰‡ã€‚');
    } catch (e) {
      throw this.handleApiError(e, 'ç”Ÿæˆå›¾ç‰‡');
    }
  }

  // ç”Ÿæˆç¼–è¾‘åçš„å›¾ç‰‡
  async generateEditedImage(imageFile, prompt, hotspot) {
    const imagePart = await this.fileToGenerativePart(imageFile);
    let textPart;
    if (hotspot && hotspot.x !== undefined && hotspot.y !== undefined) {
      textPart = { text: `Apply this edit at hotspot (${hotspot.x}, ${hotspot.y}): ${prompt}` };
    } else {
      textPart = { text: `Apply this edit to the image: ${prompt}` };
    }
    return this.callImageEditingModel([imagePart, textPart], 'ä¿®é¥°');
  }

  // ç”Ÿæˆæ»¤é•œæ•ˆæœå›¾ç‰‡
  async generateFilteredImage(imageFile, prompt) {
    const imagePart = await this.fileToGenerativePart(imageFile);
    const primaryTextPart = { text: `Apply this filter: ${prompt}` };
    try {
      return await this.callImageEditingModel([imagePart, primaryTextPart], 'æ»¤é•œ');
    } catch (error) {
      if (error instanceof Error && error.message.includes("Model responded with text instead of an image")) {
        console.warn("Original filter prompt failed. Trying a fallback without the English prefix.");
        const fallbackTextPart = { text: prompt };
        return await this.callImageEditingModel([imagePart, fallbackTextPart], 'æ»¤é•œ (fallback)');
      }
      throw error;
    }
  }

  // ç”Ÿæˆé£æ ¼åŒ–å›¾ç‰‡
  async generateStyledImage(imageFile, prompt) {
    const imagePart = await this.fileToGenerativePart(imageFile);
    const primaryTextPart = { text: `Apply this artistic style: ${prompt}` };
    try {
      return await this.callImageEditingModel([imagePart, primaryTextPart], 'åº”ç”¨é£æ ¼');
    } catch (error) {
      if (error instanceof Error && error.message.includes("Model responded with text instead of an image")) {
        console.warn("Original styled image prompt failed. Trying a fallback without the English prefix.");
        const fallbackTextPart = { text: prompt };
        return await this.callImageEditingModel([imagePart, fallbackTextPart], 'åº”ç”¨é£æ ¼ (fallback)');
      }
      throw error;
    }
  }

  // ç”Ÿæˆè°ƒæ•´åçš„å›¾ç‰‡
  async generateAdjustedImage(imageFile, prompt) {
    const imagePart = await this.fileToGenerativePart(imageFile);
    const primaryTextPart = { text: `Apply this adjustment: ${prompt}` };
    try {
      return await this.callImageEditingModel([imagePart, primaryTextPart], 'è°ƒæ•´');
    } catch (error) {
      if (error instanceof Error && error.message.includes("Model responded with text instead of an image")) {
        console.warn("Original adjustment prompt failed. Trying a fallback without the English prefix.");
        const fallbackTextPart = { text: prompt };
        return await this.callImageEditingModel([imagePart, fallbackTextPart], 'è°ƒæ•´ (fallback)');
      }
      throw error;
    }
  }

  // ç”Ÿæˆçº¹ç†æ•ˆæœå›¾ç‰‡
  async generateTexturedImage(imageFile, prompt) {
    const imagePart = await this.fileToGenerativePart(imageFile);
    const primaryTextPart = { text: `Apply this texture: ${prompt}` };
    try {
      return await this.callImageEditingModel([imagePart, primaryTextPart], 'çº¹ç†');
    } catch (error) {
      if (error instanceof Error && error.message.includes("Model responded with text instead of an image")) {
        console.warn("Original texture prompt failed. Trying a fallback without the English prefix.");
        const fallbackTextPart = { text: prompt };
        return await this.callImageEditingModel([imagePart, fallbackTextPart], 'çº¹ç† (fallback)');
      }
      throw error;
    }
  }

  // ç§»é™¤èƒŒæ™¯
  async removeBackgroundImage(imageFile) {
    const imagePart = await this.fileToGenerativePart(imageFile);
    const textPart = { text: 'Remove the background of this image, leaving only the main subject with a transparent background.' };
    return this.callImageEditingModel([imagePart, textPart], 'æŠ å›¾');
  }

  // ç”Ÿæˆèåˆå›¾ç‰‡
  async generateFusedImage(mainImage, sourceImages, prompt) {
    const fusionId = `fusion_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    try {
      console.log(`\n========== å›¾ç‰‡èåˆå¼€å§‹ [${fusionId}] ==========`);
      console.log('ğŸ“¥ è¾“å…¥å‚æ•°:', {
        mainImageName: mainImage.originalname,
        mainImageSize: mainImage.size,
        mainImageType: mainImage.mimetype,
        sourceImagesCount: sourceImages.length,
        sourceImages: sourceImages.map(f => ({
          name: f.originalname,
          size: f.size,
          type: f.mimetype
        })),
        promptLength: prompt.length,
        prompt: prompt.substring(0, 100) + (prompt.length > 100 ? '...' : '')
      });

      console.log('ğŸ”„ æ­¥éª¤1: å¤„ç†ä¸»å›¾ç‰‡...');
      const mainImagePart = await this.fileToGenerativePart(mainImage);
      console.log('âœ… ä¸»å›¾ç‰‡å¤„ç†å®Œæˆ:', {
        mimeType: mainImagePart.inlineData.mimeType,
        dataLength: mainImagePart.inlineData.data.length
      });
      
      console.log('ğŸ”„ æ­¥éª¤2: å¤„ç†é™„ä»¶å›¾ç‰‡...');
      const sourceImageParts = await Promise.all(
        sourceImages.map(async (file, index) => {
          console.log(`  å¤„ç†é™„ä»¶å›¾ç‰‡ ${index + 1}: ${file.originalname}`);
          const part = await this.fileToGenerativePart(file);
          console.log(`  âœ… é™„ä»¶å›¾ç‰‡ ${index + 1} å¤„ç†å®Œæˆ:`, {
            mimeType: part.inlineData.mimeType,
            dataLength: part.inlineData.data.length
          });
          return { ...part, index: index + 1 };
        })
      );

      console.log('ğŸ”„ æ­¥éª¤3: æ„å»ºæç¤ºè¯...');
      
      // åˆ†æç”¨æˆ·æç¤ºè¯ï¼Œæå–å…³é”®æ“ä½œ
      const userPrompt = prompt.replace(/\[ä½¿ç”¨é™„ä»¶å›¾ç‰‡\d+\]/g, '').trim();
      console.log('ğŸ“ ç”¨æˆ·åŸå§‹æç¤ºè¯:', userPrompt);
      
      // æ„å»ºæ›´å¼ºåŒ–çš„èåˆæç¤ºè¯
      let fullPrompt = `You are a professional photo editor specializing in image fusion and composition. 

CRITICAL INSTRUCTIONS:
1. You MUST create a NEW, DIFFERENT image by combining elements from ALL provided images
2. DO NOT simply return the original main image unchanged
3. You MUST generate a visually modified result that shows clear fusion/blending

Images to work with:
- PRIMARY IMAGE (base): ${mainImage.originalname}`;

      if (sourceImages.length > 0) {
        sourceImageParts.forEach(part => {
          const sourceImg = sourceImages[part.index - 1];
          fullPrompt += `\n- REFERENCE IMAGE ${part.index}: ${sourceImg.originalname} - Extract elements from this image`;
        });
      }
      
      fullPrompt += `\n\nSPECIFIC TASK: ${userPrompt}

EXECUTION REQUIREMENTS:
- Take the PRIMARY IMAGE as your base composition
- Extract specific elements, styles, colors, or features from the REFERENCE IMAGE(s)
- Apply/blend/fuse these extracted elements onto the primary image
- Ensure the result is visually DIFFERENT from the original primary image
- The output must show clear evidence of fusion/combination

IMPORTANT: The result MUST be a modified version that combines elements from both images. Do not return the original primary image unchanged.`;
      
      console.log('ğŸ¯ å¼ºåŒ–åçš„æç¤ºè¯é•¿åº¦:', fullPrompt.length);
      
      console.log('âœ… æç¤ºè¯æ„å»ºå®Œæˆ:', {
        totalLength: fullPrompt.length,
        fullPrompt: fullPrompt
      });
      
      const textPart = { text: fullPrompt };
      const allParts = [mainImagePart, ...sourceImageParts.map(p => ({ inlineData: p.inlineData })), textPart];
      
      console.log('ğŸ”„ æ­¥éª¤4: å‡†å¤‡APIè°ƒç”¨...');
      console.log('ğŸ“¦ APIè°ƒç”¨å‚æ•°:', {
        totalParts: allParts.length,
        imagePartsCount: allParts.length - 1, // å‡å»æ–‡æœ¬éƒ¨åˆ†
        textPartLength: textPart.text.length
      });
      
      console.log('ğŸš€ æ­¥éª¤5: è°ƒç”¨Google Gemini API...');
      const result = await this.callImageEditingModel(allParts, 'åˆæˆ');
      
      console.log('âœ… èåˆå®Œæˆ!', {
        fusionId,
        resultImageUrl: result.imageUrl,
        resultFilename: result.filename
      });
      console.log(`========== å›¾ç‰‡èåˆç»“æŸ [${fusionId}] ==========\n`);
      
      return result;

    } catch (e) {
      console.error(`âŒ èåˆå¤±è´¥ [${fusionId}]:`, {
        error: e.message,
        stack: e.stack
      });
      console.log(`========== å›¾ç‰‡èåˆå¤±è´¥ [${fusionId}] ==========\n`);
      throw this.handleApiError(e, 'åˆæˆ');
    }
  }

  // ç”Ÿæˆå¹´ä»£é£æ ¼å›¾ç‰‡
  async generateDecadeImage(imageFile, prompt) {
    const imagePart = await this.fileToGenerativePart(imageFile);
    
    try {
      const textPart = { text: prompt };
      const decade = this.extractDecade(prompt);
      return await this.callImageEditingModel([imagePart, textPart], `ç”Ÿæˆ ${decade} å›¾åƒ`);
    } catch (error) {
      if (error instanceof Error && error.message.includes("Model responded with text instead of an image")) {
        console.warn("Original prompt failed. Trying a fallback.");
        const decade = this.extractDecade(prompt);
        if (!decade) throw error; 
        
        const fallbackPrompt = this.getFallbackPrompt(decade);
        const fallbackTextPart = { text: fallbackPrompt };
        return await this.callImageEditingModel([imagePart, fallbackTextPart], `ç”Ÿæˆ ${decade} å›¾åƒ (fallback)`);
      }
      throw error;
    }
  }

  // æ‰¹é‡ç”Ÿæˆé£æ ¼åŒ–å›¾ç‰‡
  async generateBatchStyledImages(imageFile, prompts) {
    const results = [];
    const concurrency = 3; // å¹¶å‘é™åˆ¶
    
    for (let i = 0; i < prompts.length; i += concurrency) {
      const batch = prompts.slice(i, i + concurrency);
      const batchPromises = batch.map(async (prompt, index) => {
        try {
          const result = await this.generateStyledImage(imageFile, prompt);
          return { 
            index: i + index, 
            status: 'done', 
            url: result.imageUrl,
            filename: result.filename
          };
        } catch (error) {
          console.error(`ç”Ÿæˆç¬¬ ${i + index} å¼ å›¾ç‰‡å¤±è´¥:`, error);
          return { 
            index: i + index, 
            status: 'error', 
            error: error.message 
          };
        }
      });
      
      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);
    }
    
    return results;
  }

  // è·å–åˆ›æ„å»ºè®®
  async generateCreativeSuggestions(imageFile, type) {
    try {
      const ai = this.getGoogleAI();
      const imagePart = await this.fileToGenerativePart(imageFile);
      const textPrompt = `Analyze this image. Suggest 4 creative and interesting image ${type}s that would look good on it. Provide a very short, catchy name (2-4 words, in Chinese) and the corresponding detailed English prompt for each suggestion.`;
      const textPart = { text: textPrompt };

      const response = await ai.models.generateContent({
        model: "gemini-2.5-flash",
        contents: { parts: [imagePart, textPart] },
        config: {
          responseMimeType: "application/json",
          responseSchema: {
            type: "object",
            properties: {
              suggestions: {
                type: "array",
                items: {
                  type: "object",
                  properties: {
                    name: { type: "string", description: "A very short, catchy name for the effect in Chinese." },
                    prompt: { type: "string", description: "The detailed English prompt to achieve the effect." }
                  }
                }
              }
            }
          }
        }
      });

      const jsonString = response.text.trim();
      const result = JSON.parse(jsonString);
      return result.suggestions;
    } catch (e) {
      throw this.handleApiError(e, 'è·å–çµæ„Ÿ');
    }
  }

  // è¾…åŠ©æ–¹æ³•
  extractDecade(prompt) {
    const match = prompt.match(/(\d{4}s)/);
    return match ? match[1] : null;
  }

  getFallbackPrompt(decade) {
    return `Create a photograph of the person in this image as if they were living in the ${decade}. The photograph should capture the distinct fashion, hairstyles, and overall atmosphere of that time period. Ensure the final image is a clear photograph that looks authentic to the era.`;
  }
}

export const imageGenerationService = new ImageGenerationService();